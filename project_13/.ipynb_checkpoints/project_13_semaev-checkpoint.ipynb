{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Стохастический-градиентный-спуск\" data-toc-modified-id=\"Стохастический-градиентный-спуск-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Стохастический градиентный спуск</a></span></li><li><span><a href=\"#Градиентный-бустинг\" data-toc-modified-id=\"Градиентный-бустинг-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Градиентный бустинг</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/mikhail/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mikhail/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import re\n",
    "import timeit\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/Users/mikhail/Desktop/praktikum/project_13/toxic_comments.csv')\n",
    "    \n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74251</th>\n",
       "      <td>\"\\nI haven't paraphrased you at all, Gary.  Yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131406</th>\n",
       "      <td>I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120969</th>\n",
       "      <td>I'm sorry. I'd like to unreservedly retract my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121827</th>\n",
       "      <td>I don't know if this is exactly like the Press...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>Thank you all, we'll all improve the Wikipedia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79050</th>\n",
       "      <td>I removed\\nIf V is separable, it follows that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86098</th>\n",
       "      <td>Leave your emotions out of it. That is the exa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55703</th>\n",
       "      <td>another thing this article needs is a descript...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113939</th>\n",
       "      <td>\"\\nYou may take my word for it that it is. and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19481</th>\n",
       "      <td>20, 19 March 2010 (UTC)\\nI do. This isn't a sc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "74251   \"\\nI haven't paraphrased you at all, Gary.  Yo...      0\n",
       "131406  I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...      1\n",
       "120969  I'm sorry. I'd like to unreservedly retract my...      1\n",
       "121827  I don't know if this is exactly like the Press...      0\n",
       "4771    Thank you all, we'll all improve the Wikipedia...      0\n",
       "79050   I removed\\nIf V is separable, it follows that ...      0\n",
       "86098   Leave your emotions out of it. That is the exa...      0\n",
       "55703   another thing this article needs is a descript...      0\n",
       "113939  \"\\nYou may take my word for it that it is. and...      0\n",
       "19481   20, 19 March 2010 (UTC)\\nI do. This isn't a sc...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.101679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159571.000000\n",
       "mean        0.101679\n",
       "std         0.302226\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data['text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запишем функцию для очистки текста \n",
    "\n",
    "def clean(text):    \n",
    "    text = text.lower()    \n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запишем функцию для лемматизации текста \n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem = [lemmatizer.lemmatize(w) for w in nltk.word_tokenize(text)]\n",
    "    result = \" \".join(lem)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemma_text'] = data['text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74251</th>\n",
       "      <td>i havent paraphrased you at all gary  you comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>i havent paraphrased you at all gary you compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131406</th>\n",
       "      <td>i blocked revers i blocked revers i blocked re...</td>\n",
       "      <td>1</td>\n",
       "      <td>i blocked revers i blocked revers i blocked re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120969</th>\n",
       "      <td>im sorry id like to unreservedly retract my pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>im sorry id like to unreservedly retract my pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121827</th>\n",
       "      <td>i dont know if this is exactly like the press ...</td>\n",
       "      <td>0</td>\n",
       "      <td>i dont know if this is exactly like the press ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>thank you all well all improve the wikipedia i...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you all well all improve the wikipedia i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79050</th>\n",
       "      <td>i removed if v is separable it follows that an...</td>\n",
       "      <td>0</td>\n",
       "      <td>i removed if v is separable it follows that an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86098</th>\n",
       "      <td>leave your emotions out of it that is the exac...</td>\n",
       "      <td>0</td>\n",
       "      <td>leave your emotion out of it that is the exact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55703</th>\n",
       "      <td>another thing this article needs is a descript...</td>\n",
       "      <td>0</td>\n",
       "      <td>another thing this article need is a descripti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113939</th>\n",
       "      <td>you may take my word for it that it is andemu</td>\n",
       "      <td>0</td>\n",
       "      <td>you may take my word for it that it is andemu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19481</th>\n",
       "      <td>march  utc i do this isnt a science encycloped...</td>\n",
       "      <td>0</td>\n",
       "      <td>march utc i do this isnt a science encyclopedi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "74251   i havent paraphrased you at all gary  you comp...      0   \n",
       "131406  i blocked revers i blocked revers i blocked re...      1   \n",
       "120969  im sorry id like to unreservedly retract my pr...      1   \n",
       "121827  i dont know if this is exactly like the press ...      0   \n",
       "4771    thank you all well all improve the wikipedia i...      0   \n",
       "79050   i removed if v is separable it follows that an...      0   \n",
       "86098   leave your emotions out of it that is the exac...      0   \n",
       "55703   another thing this article needs is a descript...      0   \n",
       "113939      you may take my word for it that it is andemu      0   \n",
       "19481   march  utc i do this isnt a science encycloped...      0   \n",
       "\n",
       "                                               lemma_text  \n",
       "74251   i havent paraphrased you at all gary you compl...  \n",
       "131406  i blocked revers i blocked revers i blocked re...  \n",
       "120969  im sorry id like to unreservedly retract my pr...  \n",
       "121827  i dont know if this is exactly like the press ...  \n",
       "4771    thank you all well all improve the wikipedia i...  \n",
       "79050   i removed if v is separable it follows that an...  \n",
       "86098   leave your emotion out of it that is the exact...  \n",
       "55703   another thing this article need is a descripti...  \n",
       "113939      you may take my word for it that it is andemu  \n",
       "19481   march utc i do this isnt a science encyclopedi...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим результат\n",
    "\n",
    "data.sample(10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обозначим фичи и таргеты\n",
    "# разделим на обучающую и тестовую выборки\n",
    "\n",
    "X = data['lemma_text']\n",
    "y = data['toxic'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127656,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(127656,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(31915,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(31915,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.shape)\n",
    "display(y_train.shape)\n",
    "display(X_test.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# при помощи функции TfidfVectorizer создадим векторы величин из твитов для дальнейшего обучения\n",
    "\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим только на тренировочной выборке\n",
    "\n",
    "tf_idf = count_tf_idf.fit(X_train)\n",
    "X_train = count_tf_idf.transform(X_train)\n",
    "X_test = count_tf_idf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127656, 182944)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(31915, 182944)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.shape)\n",
    "display(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запишем функции для обучения моделей и нахождения значения метрики F1\n",
    "\n",
    "def fit(model):\n",
    "    start_time = timeit.default_timer()\n",
    "    model.fit(X_train, y_train)\n",
    "    fit_time = timeit.default_timer() - start_time\n",
    "    return fit_time\n",
    "\n",
    "def score(model, target = y_test, features = X_test):\n",
    "    start_time = timeit.default_timer()\n",
    "    score = f1_score(target, model.predict(features))\n",
    "    predict_time = timeit.default_timer() - start_time\n",
    "    return score, predict_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подберем параметры логистической регрессии\n",
    "\n",
    "#lr_parameters = {'C': (8, 9, 10), \n",
    "#                 'fit_intercept': (True, False), \n",
    "#                 'solver': ('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga')\n",
    "#                }\n",
    "#model = LogisticRegression(random_state=12345, class_weight='balanced')\n",
    "#grid = GridSearchCV(model, lr_parameters, cv=3, scoring=make_scorer(f1_score))\n",
    "#grid.fit(X_train, y_train)\n",
    "\n",
    "#grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения модели: 23.125245543000005\n",
      "Значение F1: 0.7687600174850648\n",
      "Время предсказания: 0.07919277199999897\n"
     ]
    }
   ],
   "source": [
    "# обучим модель логистической регрессии с нашими параметрами и получим значение F1 на тестовой выборке\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced', random_state=12345, C=8, fit_intercept=True, solver='newton-cg')\n",
    "lr_fit_time = fit(lr)\n",
    "print('Время обучения модели:', lr_fit_time)\n",
    "Score, time  = score(lr)\n",
    "print('Значение F1:', Score)\n",
    "print('Время предсказания:', time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подберем параметры стохастического градиентного спуска\n",
    "\n",
    "#sgdc_parameters = {\"loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"], \n",
    "#                   \"alpha\" : [0.0001, 0.001, 0.01, 0.1], \n",
    "#                   \"penalty\" : [\"l2\", \"l1\", \"none\"]\n",
    "#                  }\n",
    "#model = SGDClassifier()\n",
    "#grid = GridSearchCV(model, sgdc_parameters, cv=3, scoring=make_scorer(f1_score))\n",
    "#grid.fit(X_train, y_train)\n",
    "\n",
    "#grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения модели: 1.0492801959999838\n",
      "Значение F1: 0.7707028531663187\n",
      "Время предсказания: 0.04315898000004381\n"
     ]
    }
   ],
   "source": [
    "# обучим модель стохастического градиентного спуска с нашими параметрами и получим значение F1 на тестовой выборке\n",
    "\n",
    "sgdc = SGDClassifier(alpha=0.0001, loss='hinge', max_iter=10, n_jobs=-1, penalty='none')\n",
    "sgdc_fit_time = fit(sgdc)\n",
    "print('Время обучения модели:', sgdc_fit_time)\n",
    "Score, time  = score(sgdc)\n",
    "print('Значение F1:', Score)\n",
    "print('Время предсказания:', time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подберем параметры градиентного бустинга\n",
    "\n",
    "#lgbmc_parameters = {'max_depth': [4,6,8], 'num_leaves': [20,30,40]}\n",
    "#model = LGBMClassifier(random_state=12345)\n",
    "#grid = GridSearchCV(model, lgbmc_parameters, cv=3, scoring=make_scorer(f1_score))\n",
    "#grid.fit(X_train, y_train)\n",
    "\n",
    "#grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения модели: 333.40010837899996\n",
      "Значение F1: 0.7595350526698148\n",
      "Время предсказания: 6.37100271099996\n"
     ]
    }
   ],
   "source": [
    "# обучим модель градиентного бустинга с нашими параметрами и получим значение F1 на тестовой выборке\n",
    "\n",
    "lgbmc = LGBMClassifier(objective ='binary', random_state=12345, n_estimators=150, num_leaves=130, max_depth=40)\n",
    "lgbmc_fit_time = fit(lgbmc)\n",
    "print('Время обучения модели:', lgbmc_fit_time)\n",
    "Score, time  = score(lgbmc)\n",
    "print('Значение F1:', Score)\n",
    "print('Время предсказания:', time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- на вход получили корпус текстов\n",
    "- была проведена лемматизация полученых текстов\n",
    "- были выделены фичи и таргеты, в дальнейшем разбитые на обучающую и тестовые выборки\n",
    "- при помощи функции TfidfVectorizer были созданы векторы величин из твитов\n",
    "- были выбраны и обучены три модели классификации: логистическая регрессия, стохастический градиентный спуск и градиентный бустинг\n",
    "- все три модели показали метрику F1 выше заданного значения в 0,75\n",
    "- лучшая модель по всем параметрам (метрика F1, скорость обучения и скорость предсказания) - стохастический градиентный спуск с метрикой F1 = 0.7707028531663187"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
